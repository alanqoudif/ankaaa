import streamlit as st
from utils.openai_manager import OpenAIManager
from utils.speech_to_text import SpeechToText, preprocess_audio
import io
import time

def document_qa(vector_store, language):
    """
    Component for document Q&A functionality.
    
    Args:
        vector_store: Vector store with document embeddings
        language: Language to use for interface (English or Arabic)
    """
    # Initialize OpenAI manager and speech-to-text
    llm_manager = OpenAIManager()
    stt = SpeechToText("en" if language == "English" else "ar")
    
    # Set up the UI based on language
    if language == "English":
        st.header("Ask Questions about Omani Laws")
        query_placeholder = "What is the penalty for theft under Omani law?"
        button_text = "Ask Question"
        loading_text = "Searching legal documents..."
        no_results_text = "No relevant information found in the legal documents. Please try rephrasing your question."
        upload_text = "Or upload an audio file with your question"
        transcribing_text = "Transcribing audio..."
    else:  # Arabic
        st.header("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ©")
        query_placeholder = "Ù…Ø§ Ù‡ÙŠ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„Ø³Ø±Ù‚Ø© Ø¨Ù…ÙˆØ¬Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØŸ"
        button_text = "Ø§Ø³Ø£Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„"
        loading_text = "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©..."
        no_results_text = "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ."
        upload_text = "Ø£Ùˆ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ"
        transcribing_text = "Ø¬Ø§Ø±ÙŠ Ù†Ø³Ø® Ø§Ù„ØµÙˆØª..."
    
    # Query input
    if "qa_voice_input" not in st.session_state:
        st.session_state.qa_voice_input = ""
    
    query = st.text_area("", value=st.session_state.qa_voice_input, placeholder=query_placeholder, height=100)
    
    # Add direct speech-to-text functionality
    if language == "English":
        speech_button_text = "ğŸ¤ Click to Speak"
        speech_active_text = "ğŸ”´ Listening... Click to Stop"
        speech_placeholder = "Listening to your question..."
    else:  # Arabic
        speech_button_text = "ğŸ¤ Ø§Ù†Ù‚Ø± Ù„Ù„ØªØ­Ø¯Ø«"
        speech_active_text = "ğŸ”´ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹... Ø§Ù†Ù‚Ø± Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù"
        speech_placeholder = "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø¥Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ..."
    
    # Initialize session state for speech recording status
    if "qa_speech_active" not in st.session_state:
        st.session_state.qa_speech_active = False
    
    # Create a button for speech input
    speech_col1, speech_col2 = st.columns([1, 3])
    
    with speech_col1:
        button_text = speech_active_text if st.session_state.qa_speech_active else speech_button_text
        button_type = "primary" if st.session_state.qa_speech_active else "secondary"
        
        if st.button(button_text, key="qa_speech_button", type=button_type):
            # Toggle speech recording state
            st.session_state.qa_speech_active = not st.session_state.qa_speech_active
            st.rerun()
    
    # Add JavaScript for speech recognition
    if st.session_state.qa_speech_active:
        with speech_col2:
            st.write(speech_placeholder)
            
        # Determine the language code for speech recognition
        speech_lang = "en-US" if language == "English" else "ar-EG"
        
        # Create JavaScript for speech recognition
        js_code = f"""
        <script>
        const speechDiv = window.parent.document.querySelector('[data-testid="stMarkdown"] p');
        const textArea = window.parent.document.querySelector('textarea');
        const button = window.parent.document.querySelector('[data-testid="baseButton-secondary"]');
        
        if (typeof window.speechRecognition === 'undefined') {{
            window.speechRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            window.speechRecognition.continuous = true;
            window.speechRecognition.interimResults = true;
            window.speechRecognition.lang = '{speech_lang}';
            
            window.speechRecognition.onresult = (event) => {{
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {{
                    if (event.results[i].isFinal) {{
                        finalTranscript += event.results[i][0].transcript;
                    }}
                }}
                
                if (finalTranscript !== '') {{
                    textArea.value = finalTranscript;
                    // Trigger input event to update Streamlit state
                    const event = new Event('input', {{ bubbles: true }});
                    textArea.dispatchEvent(event);
                }}
            }};
            
            window.speechRecognition.onerror = (event) => {{
                console.error('Speech recognition error', event.error);
                button.click(); // Stop recording on error
            }};
        }}
        
        // Start recognition
        try {{
            window.speechRecognition.start();
        }} catch (e) {{
            console.error('Could not start speech recognition', e);
        }}
        </script>
        """
        st.components.v1.html(js_code, height=0)
    
    # Voice input through file upload as fallback option
    st.write(upload_text)
    
    with st.expander("Upload Audio File"):
        audio_file = st.file_uploader("", type=["wav", "mp3", "ogg"], key="qa_audio_upload")
        
        if audio_file is not None and "qa_audio_processed" not in st.session_state:
            with st.spinner(transcribing_text):
                # Read the audio file
                audio_bytes = audio_file.read()
                
                # Process the audio
                processed_audio = preprocess_audio(audio_bytes)
                
                # Transcribe the audio
                transcription = stt.transcribe_audio(processed_audio)
                
                # Update the query
                st.session_state.qa_voice_input = transcription
                st.session_state.qa_audio_processed = True
                
                # Rerun to update the text area with the transcription
                st.rerun()
        
        # Clear the processed flag if there's no audio file
        if audio_file is None and "qa_audio_processed" in st.session_state:
            st.session_state.pop("qa_audio_processed")
    
    # Process query
    if st.button(button_text):
        if not query:
            return
        
        with st.spinner(loading_text):
            # Search for relevant documents
            search_results = vector_store.search(query, k=5)
            
            if not search_results:
                st.warning(no_results_text)
                return
            
            # Gather context from search results
            context = ""
            for doc, score in search_results:
                # Only include relevant results (adjust threshold if needed)
                if score > 0.2:
                    # Add metadata about the source
                    law_name = doc.metadata.get("law_name", "Unknown Law")
                    source = doc.metadata.get("source", "Unknown Source")
                    
                    # Add to context
                    context += f"\nFrom {law_name} ({source}):\n{doc.page_content}\n"
            
            # Use the LLM to answer based on context
            answer = llm_manager.answer_legal_question(query, context, language)
            
            # Display the answer
            st.write("### Answer")
            st.write(answer)
            
            # Option to show sources
            with st.expander("Show Sources" if language == "English" else "Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø±"):
                for i, (doc, score) in enumerate(search_results):
                    law_name = doc.metadata.get("law_name", "Unknown Law")
                    source = doc.metadata.get("source", "Unknown Source")
                    page_num = doc.metadata.get("page", "Unknown")
                    
                    # Create styled header for source
                    if language == "English":
                        header = f"**Source {i+1}: {law_name}**"
                        file_info = f"*File: {source} | Page: {page_num} | Relevance: {score:.2f}*"
                    else:
                        header = f"**Ø§Ù„Ù…ØµØ¯Ø± {i+1}: {law_name}**"
                        file_info = f"*Ø§Ù„Ù…Ù„Ù: {source} | Ø§Ù„ØµÙØ­Ø©: {page_num} | Ø§Ù„ØµÙ„Ø©: {score:.2f}*"
                    
                    st.markdown(header)
                    st.markdown(file_info)
                    
                    # Display content in a more readable format
                    st.markdown("---")
                    st.markdown("##### Content:")
                    
                    # Improve the readability of the text using OpenAI
                    original_content = doc.page_content
                    
                    # Show loading spinner while improving text
                    with st.spinner("Improving text readability..." if language == "English" else "ØªØ­Ø³ÙŠÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ..."):
                        improved_content = llm_manager.improve_legal_text_readability(original_content, language)
                    
                    # Format the original content with proper styling
                    original_html = f"""
                    <details>
                        <summary style="cursor: pointer; color: #555; font-weight: bold; margin-bottom: 5px;">
                            {"Show Original Text" if language == "English" else "Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ"}
                        </summary>
                        <div dir="auto" style="background-color: #f0f0f0; padding: 10px; 
                                              border-radius: 5px; margin: 10px 0; 
                                              font-family: 'Arial', sans-serif; line-height: 1.5;">
                            {original_content}
                        </div>
                    </details>
                    """
                    
                    # Format the improved content with proper styling
                    improved_html = f"""
                    <div dir="auto" style="background-color: #f0f0f0; padding: 10px; 
                                          border-radius: 5px; margin: 10px 0; 
                                          font-family: 'Arial', sans-serif; line-height: 1.5;
                                          border-left: 4px solid #2c3e50;">
                        {improved_content}
                    </div>
                    """
                    
                    # Show the improved text by default with option to view original
                    st.markdown(f"<h6>{'Improved Text:' if language == 'English' else 'Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­Ø³Ù†:'}</h6>", unsafe_allow_html=True)
                    st.markdown(improved_html, unsafe_allow_html=True)
                    st.markdown(original_html, unsafe_allow_html=True)
                    st.markdown("---")
